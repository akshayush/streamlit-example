{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMC2QlxhV8CGGeVtZNGUhO3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshayush/streamlit-example/blob/master/MakeITTalk_Working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYTmevCfwWcq",
        "outputId": "b63d04d0-25a7-41e5-bdbe-de708a77e174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  1 13:26:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "import subprocess\n",
        "print(subprocess.getoutput('nvidia-smi'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(subprocess.getoutput('ffmpeg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hAzJF8qw0Lg",
        "outputId": "f2c9091e-33b4-4892-824c-414abc8ddc69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Hyper fast Audio and Video encoder\n",
            "usage: ffmpeg [options] [[infile options] -i infile]... {[outfile options] outfile}...\n",
            "\n",
            "Use -h to get full help or, even better, run 'man ffmpeg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yzhou359/MakeItTalk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJM7TRFgw7BG",
        "outputId": "88be7339-9404-44c2-874c-915886843db5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MakeItTalk'...\n",
            "remote: Enumerating objects: 650, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 650 (delta 57), reused 50 (delta 50), pack-reused 558\u001b[K\n",
            "Receiving objects: 100% (650/650), 26.45 MiB | 19.28 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd MakeItTalk/\n",
        "!export PYTHONPATH=/content/MakeItTalk:$PYTHONPATH\n",
        "!pip install -r requirements.txt\n",
        "!pip install tensorboardX\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jt-fMiyGw84F",
        "outputId": "4de0a191-4348-46ab-bea8-4d6807131d61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MakeItTalk\n",
            "Collecting ffmpeg-python (from -r requirements.txt (line 1))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.7.0.72)\n",
            "Collecting face_alignment (from -r requirements.txt (line 3))\n",
            "  Downloading face_alignment-1.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.2.2)\n",
            "Collecting pydub (from -r requirements.txt (line 5))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pynormalize (from -r requirements.txt (line 6))\n",
            "  Downloading pynormalize-0.1.4-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.10.0.post2)\n",
            "Collecting pysptk (from -r requirements.txt (line 9))\n",
            "  Downloading pysptk-0.2.0.tar.gz (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyworld (from -r requirements.txt (line 10))\n",
            "  Downloading pyworld-0.3.3.tar.gz (218 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting librosa (from -r requirements.txt (line 8))\n",
            "  Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting resemblyzer (from -r requirements.txt (line 12))\n",
            "  Downloading Resemblyzer-0.1.3-py3-none-any.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 8)) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 8)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 8)) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa->-r requirements.txt (line 8))\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 8)) (0.56.4)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 8)) (23.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python->-r requirements.txt (line 1)) (0.18.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from face_alignment->-r requirements.txt (line 3)) (2.0.1+cu118)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from face_alignment->-r requirements.txt (line 3)) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from face_alignment->-r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.1.0)\n",
            "Collecting mutagen>=1.40.0 (from pynormalize->-r requirements.txt (line 6))\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: cython>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from pysptk->-r requirements.txt (line 9)) (0.29.35)\n",
            "Collecting webrtcvad>=2.0.10 (from resemblyzer->-r requirements.txt (line 12))\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing (from resemblyzer->-r requirements.txt (line 12))\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 7)) (2.21)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa->-r requirements.txt (line 8)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa->-r requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 8)) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 8)) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment->-r requirements.txt (line 3)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment->-r requirements.txt (line 3)) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment->-r requirements.txt (line 3)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment->-r requirements.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->face_alignment->-r requirements.txt (line 3)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->face_alignment->-r requirements.txt (line 3)) (16.0.6)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->face_alignment->-r requirements.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->face_alignment->-r requirements.txt (line 3)) (1.3.0)\n",
            "Building wheels for collected packages: pysptk, pyworld, webrtcvad, typing\n",
            "  Building wheel for pysptk (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysptk: filename=pysptk-0.2.0-cp310-cp310-linux_x86_64.whl size=1282435 sha256=b1602d429d94af36235eb3e132bb2f39a2b979b6743bdefd4f7dc605101fcbf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/2a/ed/6a829dcdfd2a67af80144fcdfc9c3f31eac108fafba4fceb59\n",
            "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.3-cp310-cp310-linux_x86_64.whl size=887666 sha256=9fcf862e7d2f278185efecbfe1df571f4aee6464461690ae457d18b56edba8a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/50/a9/36b47c7f055bbee666a2b5718aaf85bce2152ef90f9bd10697\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp310-cp310-linux_x86_64.whl size=81210 sha256=1c808c6fe0788ce4dc8e0ed0002527eb01cacd90ec6fa8834859532587750096\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/2b/84/ac7bacfe8c68a87c1ee3dd3c66818a54c71599abf308e8eb35\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26305 sha256=6fe4ac1e2e985b58940e6face5592025fe046bfebc495583cd45d7b57883a581\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n",
            "Successfully built pysptk pyworld webrtcvad typing\n",
            "Installing collected packages: webrtcvad, pydub, typing, pyworld, mutagen, ffmpeg-python, resampy, pysptk, pynormalize, librosa, resemblyzer, face_alignment\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.0.post2\n",
            "    Uninstalling librosa-0.10.0.post2:\n",
            "      Successfully uninstalled librosa-0.10.0.post2\n",
            "Successfully installed face_alignment-1.4.0 ffmpeg-python-0.2.0 librosa-0.9.1 mutagen-1.46.0 pydub-0.25.1 pynormalize-0.1.4 pysptk-0.2.0 pyworld-0.3.3 resampy-0.4.2 resemblyzer-0.1.3 typing-3.7.4.3 webrtcvad-2.0.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Collecting protobuf>=4.22.3 (from tensorboardX)\n",
            "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, tensorboardX\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed protobuf-4.23.3 tensorboardX-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir examples/dump\n",
        "!mkdir examples/ckpt\n",
        "!pip install gdown\n",
        "!gdown -O examples/ckpt/ckpt_autovc.pth https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
        "!gdown -O examples/ckpt/ckpt_content_branch.pth https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
        "!gdown -O examples/ckpt/ckpt_speaker_branch.pth https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
        "!gdown -O examples/ckpt/ckpt_116_i2i_comb.pth https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
        "!gdown -O examples/dump/emb.pickle https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JILkX7TzBfj1",
        "outputId": "b88d6d47-7452-4dee-8ecf-7d266bb6056f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
            "To: /content/MakeItTalk/examples/ckpt/ckpt_autovc.pth\n",
            "100% 172M/172M [00:03<00:00, 53.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
            "To: /content/MakeItTalk/examples/ckpt/ckpt_content_branch.pth\n",
            "100% 7.88M/7.88M [00:00<00:00, 33.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
            "To: /content/MakeItTalk/examples/ckpt/ckpt_speaker_branch.pth\n",
            "100% 15.4M/15.4M [00:00<00:00, 61.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
            "To: /content/MakeItTalk/examples/ckpt/ckpt_116_i2i_comb.pth\n",
            "100% 839M/839M [00:13<00:00, 61.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI\n",
            "To: /content/MakeItTalk/examples/dump/emb.pickle\n",
            "100% 30.9M/30.9M [00:00<00:00, 119MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MakeItTalk/\n",
        "import sys\n",
        "sys.path.append(\"thirdparty/AdaptiveWingLoss\")\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import argparse\n",
        "from src.approaches.train_image_translation import Image_translation_block\n",
        "import torch\n",
        "import pickle\n",
        "import face_alignment\n",
        "from src.autovc.AutoVC_mel_Convertor_retrain_version import AutoVC_mel_Convertor\n",
        "import shutil\n",
        "import time\n",
        "import util.utils as util\n",
        "from scipy.signal import savgol_filter\n",
        "from src.approaches.train_audio2landmark import Audio2landmark_model"
      ],
      "metadata": {
        "id": "ftYPeiTSCZ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8013f545-4052-438f-eade-79a59ecaa020"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'MakeItTalk/'\n",
            "/content/MakeItTalk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv5Yn2PQiyyK",
        "outputId": "c8545531-9a7b-42c4-a5ca-b6fb8081e335"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement core (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for core\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#default_head_name = 'paint_boy'\n",
        "default_head_name = 'stuart_riley'           # the image name (with no .jpg) to animate\n",
        "ADD_NAIVE_EYE = True                 # whether add naive eye blink\n",
        "CLOSE_INPUT_FACE_MOUTH = False       # if your image has an opened mouth, put this as True, else False\n",
        "AMP_LIP_SHAPE_X = 2.                 # amplify the lip motion in horizontal direction\n",
        "AMP_LIP_SHAPE_Y = 2.                 # amplify the lip motion in vertical direction\n",
        "AMP_HEAD_POSE_MOTION = 0.7"
      ],
      "metadata": {
        "id": "ewycXs3PChFR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--jpg', type=str, default='{}.jpg'.format(default_head_name))\n",
        "parser.add_argument('--close_input_face_mouth', default=CLOSE_INPUT_FACE_MOUTH, action='store_true')\n",
        "\n",
        "parser.add_argument('--load_AUTOVC_name', type=str, default='examples/ckpt/ckpt_autovc.pth')\n",
        "parser.add_argument('--load_a2l_G_name', type=str, default='examples/ckpt/ckpt_speaker_branch.pth')\n",
        "parser.add_argument('--load_a2l_C_name', type=str, default='examples/ckpt/ckpt_content_branch.pth') #ckpt_audio2landmark_c.pth')\n",
        "parser.add_argument('--load_G_name', type=str, default='examples/ckpt/ckpt_116_i2i_comb.pth') #ckpt_image2image.pth') #ckpt_i2i_finetune_150.pth') #c\n",
        "\n",
        "parser.add_argument('--amp_lip_x', type=float, default=AMP_LIP_SHAPE_X)\n",
        "parser.add_argument('--amp_lip_y', type=float, default=AMP_LIP_SHAPE_Y)\n",
        "parser.add_argument('--amp_pos', type=float, default=AMP_HEAD_POSE_MOTION)\n",
        "parser.add_argument('--reuse_train_emb_list', type=str, nargs='+', default=[]) #  ['iWeklsXc0H8']) #['45hn7-LXDX8']) #['E_kmpT-EfOg']) #'iWeklsXc0H8', '29k8RtSUjE0', '45hn7-LXDX8',\n",
        "parser.add_argument('--add_audio_in', default=False, action='store_true')\n",
        "parser.add_argument('--comb_fan_awing', default=False, action='store_true')\n",
        "parser.add_argument('--output_folder', type=str, default='examples')\n",
        "\n",
        "parser.add_argument('--test_end2end', default=True, action='store_true')\n",
        "parser.add_argument('--dump_dir', type=str, default='', help='')\n",
        "parser.add_argument('--pos_dim', default=7, type=int)\n",
        "parser.add_argument('--use_prior_net', default=True, action='store_true')\n",
        "parser.add_argument('--transformer_d_model', default=32, type=int)\n",
        "parser.add_argument('--transformer_N', default=2, type=int)\n",
        "parser.add_argument('--transformer_heads', default=2, type=int)\n",
        "parser.add_argument('--spk_emb_enc_size', default=16, type=int)\n",
        "parser.add_argument('--init_content_encoder', type=str, default='')\n",
        "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
        "parser.add_argument('--reg_lr', type=float, default=1e-6, help='weight decay')\n",
        "parser.add_argument('--write', default=False, action='store_true')\n",
        "parser.add_argument('--segment_batch_size', type=int, default=1, help='batch size')\n",
        "parser.add_argument('--emb_coef', default=3.0, type=float)\n",
        "parser.add_argument('--lambda_laplacian_smooth_loss', default=1.0, type=float)\n",
        "parser.add_argument('--use_11spk_only', default=False, action='store_true')\n",
        "parser.add_argument('-f')\n",
        "\n",
        "opt_parser = parser.parse_args()"
      ],
      "metadata": {
        "id": "cwPZQrP1Ctv0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img =cv2.imread('examples/' + opt_parser.jpg)\n",
        "predictor = face_alignment.FaceAlignment(face_alignment.LandmarksType.THREE_D, device='cpu', flip_input=True)\n",
        "shapes = predictor.get_landmarks(img)\n",
        "if (not shapes or len(shapes) != 1):\n",
        "    print('Cannot detect face landmarks. Exit.')\n",
        "    exit(-1)\n",
        "shape_3d = shapes[0]\n",
        "\n",
        "if(opt_parser.close_input_face_mouth):\n",
        "    util.close_input_face_mouth(shape_3d)"
      ],
      "metadata": {
        "id": "A0diwHklCu6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a41e3de-06b4-496e-fa82-cbb33f661c36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n",
            "100%|██████████| 85.7M/85.7M [00:02<00:00, 31.9MB/s]\n",
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/3DFAN4-4a694010b9.zip\" to /root/.cache/torch/hub/checkpoints/3DFAN4-4a694010b9.zip\n",
            "100%|██████████| 91.9M/91.9M [00:07<00:00, 12.3MB/s]\n",
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/depth-6c4283c0e0.zip\" to /root/.cache/torch/hub/checkpoints/depth-6c4283c0e0.zip\n",
            "100%|██████████| 224M/224M [00:22<00:00, 10.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "shape_3d[48:, 0] = (shape_3d[48:, 0] - np.mean(shape_3d[48:, 0])) * 1.05 + np.mean(shape_3d[48:, 0]) # wider lips\n",
        "shape_3d[49:54, 1] += 0.           # thinner upper lip\n",
        "shape_3d[55:60, 1] -= 1.           # thinner lower lip\n",
        "shape_3d[[37,38,43,44], 1] -=2.    # larger eyes\n",
        "shape_3d[[40,41,46,47], 1] +=2.    # larger eyes"
      ],
      "metadata": {
        "id": "bboebHz_DFzt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "shape_3d, scale, shift = util.norm_input_face(shape_3d)"
      ],
      "metadata": {
        "id": "kTntYyjHDL9_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "au_data = []\n",
        "au_emb = []\n",
        "ains = glob.glob1('examples', '*.wav')\n",
        "ains = [item for item in ains if item is not 'tmp.wav']\n",
        "ains.sort()\n",
        "for ain in ains:\n",
        "    os.system('ffmpeg -y -loglevel error -i examples/{} -ar 16000 examples/tmp.wav'.format(ain))\n",
        "    shutil.copyfile('examples/tmp.wav', 'examples/{}'.format(ain))\n",
        "\n",
        "    # au embedding\n",
        "    from thirdparty.resemblyer_util.speaker_emb import get_spk_emb\n",
        "    me, ae = get_spk_emb('examples/{}'.format(ain))\n",
        "    au_emb.append(me.reshape(-1))\n",
        "\n",
        "    print('Processing audio file', ain)\n",
        "    c = AutoVC_mel_Convertor('examples')\n",
        "\n",
        "    au_data_i = c.convert_single_wav_to_autovc_input(audio_filename=os.path.join('examples', ain),\n",
        "           autovc_model_path=opt_parser.load_AUTOVC_name)\n",
        "    au_data += au_data_i\n",
        "if(os.path.isfile('examples/tmp.wav')):\n",
        "    os.remove('examples/tmp.wav')\n",
        "\n",
        "# landmark fake placeholder\n",
        "fl_data = []\n",
        "rot_tran, rot_quat, anchor_t_shape = [], [], []\n",
        "for au, info in au_data:\n",
        "    au_length = au.shape[0]\n",
        "    fl = np.zeros(shape=(au_length, 68 * 3))\n",
        "    fl_data.append((fl, info))\n",
        "    rot_tran.append(np.zeros(shape=(au_length, 3, 4)))\n",
        "    rot_quat.append(np.zeros(shape=(au_length, 4)))\n",
        "    anchor_t_shape.append(np.zeros(shape=(au_length, 68 * 3)))\n",
        "\n",
        "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl.pickle'))):\n",
        "    os.remove(os.path.join('examples', 'dump', 'random_val_fl.pickle'))\n",
        "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))):\n",
        "    os.remove(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))\n",
        "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_au.pickle'))):\n",
        "    os.remove(os.path.join('examples', 'dump', 'random_val_au.pickle'))\n",
        "if (os.path.exists(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))):\n",
        "    os.remove(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))\n",
        "\n",
        "with open(os.path.join('examples', 'dump', 'random_val_fl.pickle'), 'wb') as fp:\n",
        "    pickle.dump(fl_data, fp)\n",
        "with open(os.path.join('examples', 'dump', 'random_val_au.pickle'), 'wb') as fp:\n",
        "    pickle.dump(au_data, fp)\n",
        "with open(os.path.join('examples', 'dump', 'random_val_gaze.pickle'), 'wb') as fp:\n",
        "    gaze = {'rot_trans':rot_tran, 'rot_quat':rot_quat, 'anchor_t_shape':anchor_t_shape}\n",
        "    pickle.dump(gaze, fp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErN9QfXdDNdb",
        "outputId": "8d2cf650-ba7e-4e2a-fa4a-a8cd716f1bcc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:4: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:4: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<ipython-input-10-50fe2f4fa52c>:4: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  ains = [item for item in ains if item is not 'tmp.wav']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cuda in 7.11 seconds.\n",
            "Processing audio file M6_04_16k.wav\n",
            "0 out of 0 are in this portion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/MakeItTalk/src/autovc/retrain_version/vocoder_spec/extract_f0_func.py:97: FutureWarning: Pass sr=16000, n_fft=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mel_basis = mel(16000, 1024, fmin=90, fmax=7600, n_mels=80).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cuda in 0.01 seconds.\n",
            "source shape: torch.Size([1, 320, 80]) torch.Size([1, 256]) torch.Size([1, 256]) torch.Size([1, 320, 257])\n",
            "converted shape: torch.Size([1, 320, 80]) torch.Size([1, 640])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "model = Audio2landmark_model(opt_parser, jpg_shape=shape_3d)\n",
        "if(len(opt_parser.reuse_train_emb_list) == 0):\n",
        "    model.test(au_emb=au_emb)\n",
        "else:\n",
        "    model.test(au_emb=None)"
      ],
      "metadata": {
        "id": "rnDcl-RsDVIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929870ef-ba56-4191-d044-d397332e6bcb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MakeItTalk\n",
            "Run on device: cuda\n",
            "Loading Data random_val\n",
            "EVAL num videos: 1\n",
            "G: Running on cuda, total num params = 3.00M\n",
            "======== LOAD PRETRAINED FACE ID MODEL examples/ckpt/ckpt_speaker_branch.pth =========\n",
            "======== LOAD PRETRAINED FACE ID MODEL examples/ckpt/ckpt_content_branch.pth =========\n",
            "====================================\n",
            "48uYS3bHIA8\n",
            "YAZuSHvwVC0\n",
            "0yaLdVk_UyQ\n",
            "E_kmpT-EfOg\n",
            "fQR31F7L3ww\n",
            "JPMZAOGGHh8\n",
            "W6uRNCJmdtI\n",
            "2KL8PfQPmBg\n",
            "p575B7k07a8\n",
            "iUoAe2gXKE4\n",
            "HH-iOC056aQ\n",
            "S8fiWqrZEew\n",
            "ROWN2ssXek8\n",
            "irx71tYyI-Q\n",
            "me6cdZCM2FY\n",
            "OkqHtWOFliM\n",
            "OfPKHc6w2vw\n",
            "1lh57VnuaKE\n",
            "_ldiVrXgZKc\n",
            "H1Xnb_rtgqY\n",
            "45hn7-LXDX8\n",
            "bs7ZWVqAGCU\n",
            "UElg0R7fmlk\n",
            "bCs5SoifsiY\n",
            "1Lx_ZqrK1bM\n",
            "RrnL6Pcjjbw\n",
            "sRbWv2R2hxE\n",
            "wJmdE0G4sEg\n",
            "hE-4e1vEiT8\n",
            "XXbxe3fCQqg\n",
            "02HOKnTjBlQ\n",
            "wAAMEC1OsRc\n",
            "7Sk--XzX8b0\n",
            "I5Lm0Qce5kg\n",
            "qLxfiUMYgQg\n",
            "_VpqWkdcaqM\n",
            "ljIkW4uVVQY\n",
            "5m5iPZNJS6c\n",
            "J-NPsvtQ8lE\n",
            "gOrQyrbptGo\n",
            "43BiUVlNy58\n",
            "swLghyvhoqA\n",
            "X3FCAoFnmdA\n",
            "2NiCRAmwoc4\n",
            "KVUf0J2LAaA\n",
            "YtZS9hH1j24\n",
            "5fZj9Fzi5K0\n",
            "wbWKG26ebMw\n",
            "QgNlXur0wrs\n",
            "qek_5m1MRik\n",
            "rmFsUV5ICKk\n",
            "bEdGv1wixF4\n",
            "ljh5PB6Utsc\n",
            "izudwWTXuUk\n",
            "B08yOvYMF7Y\n",
            "UEmI4r5G-5Y\n",
            "Scujgl9GbHA\n",
            "sxCbrYjBsGA\n",
            "qvQC0w3y_Fo\n",
            "bXpavyiCu10\n",
            "iWeklsXc0H8\n",
            "H00oAfd_GsM\n",
            "Z7WRt--g-h4\n",
            "29k8RtSUjE0\n",
            "E0zgrhQ0QDw\n",
            "9KhvSxKE6Mc\n",
            "qLNvRwMkhik\n",
            "====================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/MakeItTalk/src/approaches/train_audio2landmark.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  z = torch.tensor(torch.zeros(aus.shape[0], 128), requires_grad=False, dtype=torch.float).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "examples/M6_04_16k.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fls = glob.glob1('examples', 'pred_fls_*.txt')\n",
        "fls.sort()\n",
        "\n",
        "for i in range(0,len(fls)):\n",
        "    fl = np.loadtxt(os.path.join('examples', fls[i])).reshape((-1, 68,3))\n",
        "    fl[:, :, 0:2] = -fl[:, :, 0:2]\n",
        "    fl[:, :, 0:2] = fl[:, :, 0:2] / scale - shift\n",
        "\n",
        "    if (ADD_NAIVE_EYE):\n",
        "        fl = util.add_naive_eye(fl)\n",
        "\n",
        "    # additional smooth\n",
        "    fl = fl.reshape((-1, 204))\n",
        "    fl[:, :48 * 3] = savgol_filter(fl[:, :48 * 3], 15, 3, axis=0)\n",
        "    fl[:, 48*3:] = savgol_filter(fl[:, 48*3:], 5, 3, axis=0)\n",
        "    fl = fl.reshape((-1, 68, 3))\n",
        "\n",
        "    ''' STEP 6: Imag2image translation '''\n",
        "    model = Image_translation_block(opt_parser, single_test=True)\n",
        "    with torch.no_grad():\n",
        "        model.single_test(jpg=img, fls=fl, filename=fls[i], prefix=opt_parser.jpg.split('.')[0])\n",
        "        print('finish image2image gen')\n",
        "    os.remove(os.path.join('examples', fls[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFFF4s0ysPW5",
        "outputId": "aaabc753-8f82-4662-c4f2-3295a03e5dd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run on device cuda\n",
            "Time - only video: 10.1021089553833\n",
            "Time - ffmpeg add audio: 12.518882989883423\n",
            "finish image2image gen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "for ain in ains:\n",
        "  OUTPUT_MP4_NAME = '{}_pred_fls_{}_audio_embed.mp4'.format(\n",
        "    opt_parser.jpg.split('.')[0],\n",
        "    ain.split('.')[0]\n",
        "    )\n",
        "  mp4 = open('examples/{}'.format(OUTPUT_MP4_NAME),'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  print('Display a[0nimation: examples/{}'.format(OUTPUT_MP4_NAME))\n",
        "  display(HTML(\"\"\"{0}\"\"\" % data_url))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "GJlg0WxosUIv",
        "outputId": "deaf4631-78e0-4dc4-d450-1522d5ac432e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Display a[0nimation: examples/stuart_riley_pred_fls_M6_04_16k_audio_embed.mp4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-86a89550d3ab>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mdata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data:video/mp4;base64,\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Display a[0nimation: examples/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_MP4_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"{0}\"\"\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdata_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
          ]
        }
      ]
    }
  ]
}